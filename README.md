<html>
<body>
<table>
<tr>
<td align="center" colspan="4">Shiv Nadar University</td></tr>
<tr><td align="center">TITLE</td><td align="center">STATUS</td><td align="center">DESCRIPTION</td><td align="center">SUGGESTION</td></tr>
<tr><td> Page Title</td><td>Found</td><td> This website consists of 47 characters.</td><td> The Page title should consist of 9 to 60 words.</td></tr>
<tr><td>Meta Description</td><td>Not Found</td> <td>The websites meta description length is 0 characters.</td><td>Use keywords in your meta description tag and make sure that the meta description length does not exceed more than 150 characters.</td></tr>
<tr><td> Meta Keywords</td><td>Found</td><td>There is no meta keyword found in the web page.</td><td>For meta keyword, use synonyms and unique keywords but it is not required these days much for web pages.</td></tr>
<tr><td> Keywords Test</td><td>Not found</td><td>The most common keywords are not appearing in one or more of the meta-tags above.</td><td> The primary keywords should appear in your meta-tags to help identify the topic of the webpage to search engines.</td></tr>
<tr><td>Heading Status</td><td>Not found</td><td>No heading tag (H1 and H2) found in the web page.</td><td>H1 is an important factor influencing page ranking and there should be a relevant heading tag in the web page which can make it easy to search.</td></tr>
<tr><td> Robots.txt Test</td><td>Found</td><td> This site consists of one robots.txt.</td><td>A robots.txt file should be present as it gives instructions to web robots about the pages the website owner that doesn’t wish to be ‘crawled’.  For instance, if you didn’t want your images to be listed by Google and other search engines, you can block them using your robots.txt file.</td></tr>
<tr><td> Sitemap Test</td><td>Found</td><td> This website consists of one sitemap test.</td><td>Having sitemap not only makes the navigation easy and better visibility by search engines.It also offer the opportunity to inform search engines immediately about any changes on your site.</td></tr>
<tr><td> Underscores in Links Test</td><td>Not found</td><td>The web site does not contain any underscore links. <td>A link should not contain underscore but we should use dash(-) for a good link name. </td> </tr>
<tr><td> SEO Friendly URL Test</td><td>Not found</td><td>In this web page 76 internal URLs are found which is not SEO friendly</td>  <td>In this, uppercase alphabets and special characters(eg:- & ? %) are not supported by SEO but it only contains lowercase alphabets, numbers,slashes(/) and dash(-) only.</td></tr>
<tr><td> Image Alt Test</td><td>Not found</td><td>The webpage has 73 'img' tags and 69 of them missing the required 'alt' attribute.</td><td> The image alt attribute description should be a meaningful description of the image. The description should make it clear what is in the image.</td></tr>
<tr><td>Incline CSS Test</td><td>Not Found</td><td>The webpage is using 185 inline CSS styles.</td><td>We should move all the inline CSS rules into an external file in order to make the page "lighter" in weight and decrease the code to text ratio whereas, for each style attribute found, you must properly move all declarations in the external CSS file and remove the style attribute.</td></tr>
<tr><td> Depreciated HTML Tags</td><td>Not found</td> <td>There might be many HTML tags, which you are using in your webpage but they are depreciated and many of the search engines do not support them.</td><td>First identify the web page's code and all deprecated HTML tags listed above and replace them with proper tags or CSS rules. </tr>
<tr><td> Noindex Tag Checker</td><td>Found</td><td>This webpage does not use the noindex meta tag.</td><td> The webpage will be read and indexed by search engines.</td></tr>
<tr><td> HTML Page Size Test</td><td>Found</td><td>HTML page size is 26.87 Kb.</td><td> The average web page size of 33 Kb. 
This leads to a faster page loading time than average.</td></tr>
<tr><td> HTML Compression</td><td>Found</td><td>The page is compressed using gzip compression on the code. HTML is compressed from 141.83 Kb to 26.87 Kb (81 % size savings).</td><td> This helps ensure a faster loading web page and improved user experience.</td></tr>
<tr><td> NoFollow Tag Checker</td><td>Found</td><td> The webpage does not use the nofollow meta tag.</td><td>Here in the web page, the search engines will crawl all links from the webpage.</td></tr>
<tr><td>Site Loading Speed Test</td><td>Not Found</td><td>The site loading time is around 6.305 seconds and is over the average loading speed which is 5 seconds.</td><td>In order to resolve this problem you are advised to:
<UL>
<li>Minimize HTTP requests</li>
<li>Use Gzip compression </li>
<li>Use HTTP caching</li>
<li>Move all CSS style rules into a single, external and minified CSS file</li>
<li>Minify all JS files and, if possible, try combining them into a single external JS file</li>
<li>Include external CSS files before external JS files</li>
<li>Place your JS scripts at the bottom of your page</li>
<li>Optimize images</li>
<li>Reduce redirects</li>
<li>Reduce the number of plug-ins</li>
</UL></td></tr>
<tr><td>Page Rank</td><td>Found</td><td>The Page Rank for this web page is 6.</td><td>The page rank for this web page is good. The higher the page rank, it is more likely to appear at the top of the search engine result.</td></tr>
<tr><td>Social Media Check</td><td>Found</td><td>The web page is connected with several social media: Facebook, Twitter, GooglePlus;</td><td>Social Media Links may boost your search rank and profile ranks in search engine.</td></tr>
<tr><td>JavaScript Error Checker</td><td>Not Found</td><td>Found 2 JavaScript error in the web page.</td><td>First of all, we have to locate the source of errors,if we are using JS plugins or other third party code, one should carefully read the documentation and use Syntax errors (a typo or missing character) to fix.</td></tr>
<tr><td>IP Canonicalization Test</td><td>Not Found</td><td>Your site's IP 52.66.78.73 does not redirect to your site's domain name.</td><td>If a search engine indexes your site under both its IP and domain name which may cause duplicate content problem.</td></tr>
</table> 
</body>
</html>
